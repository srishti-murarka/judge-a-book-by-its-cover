{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Judge a Book by its cover   \n",
        "*Srishti Murarka*  \n",
        "DA623: Multimodal Data Analysis (Winter 2025)  \n",
        "Date: May 9, 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Motivation\n",
        "\n",
        "With the rapid growth of digital libraries and online bookstores, automatic genre classification of books has become increasingly important for search, recommendation, and organization. I chose this project because it asks a deceptively simple question: **Can we predict a bookâ€™s genre using only its title?** Titles are often short, creative, and ambiguous, making this a challenging and interesting problem for machine learning and natural language processing. This project also connects to real-world applications in information retrieval and recommender systems, and provides a foundation for exploring multimodal learning.\n",
        "\n",
        "---\n",
        "\n",
        "## Historical Perspective\n",
        "\n",
        "Book genre classification has a rich history across several modalities:\n",
        "\n",
        "- **Text-based approaches:** Early work used book summaries or full text for genre prediction, achieving high accuracy but requiring extensive data and computation.\n",
        "- **Image-based approaches:** Recent projects use book cover images with deep learning (e.g., VGG16) for genre prediction, as in [HimanshuRaj98/book-genre-classification][3].\n",
        "- **Multimodal approaches:** Combining titles, summaries, and cover images has shown improved accuracy, leveraging the strengths of each data type.\n",
        "- **Title-only approaches:** Some studies, including this project, focus on titles for their accessibility and speed, though with lower accuracy compared to richer inputs.\n",
        "\n",
        "This project benchmarks classic and deep learning models using only book titles, and discusses how multimodal data could further improve results.\n",
        "\n",
        "---\n",
        "\n",
        "## Learning & Explanation\n",
        "\n",
        "### Dataset\n",
        "\n",
        "- **Source:** [Judging a Book by its Cover][2]\n",
        "- **Size:** 207,572 books, 32 genres\n",
        "- **Fields:** ASIN, image URL, title, author, genre\n",
        "- **For this project:** Only the title is used as input, with the genre as the label.\n",
        "\n",
        "Example data row:\n",
        "\n",
        "| Label | Category Name                | Size   |\n",
        "|-------|-----------------------------|--------|\n",
        "| 4     | Children's Books            | 13,605 |\n",
        "| 22    | Romance                     | 4,291  |\n",
        "| 23    | Science & Math              | 9,276  |\n",
        "| 17    | Mystery, Thriller & Suspense| 1,998  |\n",
        "| 29    | Travel                      | 18,338 |\n",
        "| ...   | ...                         | ...    |\n",
        "\n",
        "### Algorithms Used\n",
        "\n",
        "1. **Bag-of-Words + Feed-Forward Neural Network**  \n",
        "   - Converts titles into word count vectors (ignores order/context).\n",
        "   - Simple neural network for classification.\n",
        "\n",
        "2. **TF-IDF + Classical ML Models**  \n",
        "   - TF-IDF weighs rare words more heavily.\n",
        "   - Models: Logistic Regression, Multinomial Naive Bayes, Multi-Layer Perceptron, XGBoost.\n",
        "\n",
        "3. **RNN/LSTM + GloVe Embeddings**  \n",
        "   - Uses pre-trained GloVe vectors for word embeddings.\n",
        "   - RNNs/LSTMs capture word order and context in titles.\n",
        "\n",
        "---\n",
        "\n",
        "## Code / Experiments\n",
        "\n",
        "### Data Loading & Preprocessing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Wn1QKseczjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pezvWjUlcqCj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "30mULSKed5Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('books.csv', header=None, names=['ASIN', 'FILENAME', 'IMAGE_URL', 'TITLE', 'AUTHOR', 'CATEGORY_ID', 'CATEGORY'])"
      ],
      "metadata": {
        "id": "uk5WEO-aeUD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only keep title and genre"
      ],
      "metadata": {
        "id": "OkN2N-52eTzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['TITLE', 'CATEGORY']]\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "XW2obAaEeiXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show class distribution"
      ],
      "metadata": {
        "id": "rOM9kF0Zek98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['CATEGORY'].value_counts().plot(kind='bar', figsize=(12,4), title='Genre Distribution')"
      ],
      "metadata": {
        "id": "k3qtRVzyeoOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Text Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "oZnG4VmLer-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "text = text.lower()\n",
        "text = re.sub(r'[^a-z\\s]', '', text)\n",
        "return text\n",
        "\n",
        "df['CLEAN_TITLE'] = df['TITLE'].apply(clean_text)"
      ],
      "metadata": {
        "id": "SU_nSO2Qe2n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### TF-IDF + Logistic Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "wmkAcEt6e43q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X = df['CLEAN_TITLE']\n",
        "y = df['CATEGORY']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "UC_qVa_re6Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Model Comparison (Summary Table)\n",
        "\n",
        "| Model                           | Accuracy   |\n",
        "|----------------------------------|------------|\n",
        "| Bag-of-Words + NN               | ~60%       |\n",
        "| TF-IDF + Logistic Regression    | ~65%       |\n",
        "| TF-IDF + Naive Bayes            | ~62%       |\n",
        "| RNN/LSTM + GloVe                | ~66%       |\n",
        "\n",
        "*Note: Actual results may vary depending on data splits and preprocessing.*\n",
        "\n",
        "### Visualization: Confusion Matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "0ChEfeC2e9Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
        "plt.figure(figsize=(14,10))\n",
        "sns.heatmap(cm, xticklabels=clf.classes_, yticklabels=clf.classes_, cmap='Blues', fmt='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hz57RT-RfAZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Reflections\n",
        "\n",
        "### What Surprised Me\n",
        "\n",
        "- **Short titles are limiting:** Many titles are too vague or creative to give strong genre cues.\n",
        "- **Classical models are strong:** TF-IDF with Logistic Regression is a surprisingly strong baseline.\n",
        "- **Deep learning is not always better:** With only titles, deep models like LSTM do not outperform classical models by much.\n",
        "\n",
        "### Scope for Improvement\n",
        "\n",
        "- **Multimodal learning:** Combining titles with book cover images or summaries could provide richer features and boost accuracy.\n",
        "- **Handling multi-label genres:** Some books fit multiple genres, but current models assume only one label per book.\n",
        "- **Data balance:** Addressing class imbalance could help underrepresented genres.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "YDNYrrMpfDeH"
      }
    }
  ]
}