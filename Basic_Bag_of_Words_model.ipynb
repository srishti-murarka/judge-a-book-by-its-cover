{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploratory Analysis and Classification of books by Genre on Amazon Book Dataset using a simple feed forward neural net.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Following libraries need to be installed \n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- tensorflow\n",
    "- tflearn\n",
    "- jupyter notebook\n",
    "\n",
    "Download the book dataset from https://github.com/uchidalab/book-dataset/tree/master/Task2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Importing our Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/book32-listing.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>761183272</th>\n",
       "      <th>0761183272.jpg</th>\n",
       "      <th>http://ecx.images-amazon.com/images/I/61Y5cOdHJbL.jpg</th>\n",
       "      <th>Mom's Family Wall Calendar 2016</th>\n",
       "      <th>Sandra Boynton</th>\n",
       "      <th>3</th>\n",
       "      <th>Calendars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623439671</td>\n",
       "      <td>1623439671.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61t-hrSw...</td>\n",
       "      <td>Doug the Pug 2016 Wall Calendar</td>\n",
       "      <td>Doug the Pug</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00O80WC6I</td>\n",
       "      <td>B00O80WC6I.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41X-KQqs...</td>\n",
       "      <td>Moleskine 2016 Weekly Notebook, 12M, Large, Bl...</td>\n",
       "      <td>Moleskine</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761182187</td>\n",
       "      <td>0761182187.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61j-4gxJ...</td>\n",
       "      <td>365 Cats Color Page-A-Day Calendar 2016</td>\n",
       "      <td>Workman Publishing</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1578052084</td>\n",
       "      <td>1578052084.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51Ry4Tsq...</td>\n",
       "      <td>Sierra Club Engagement Calendar 2016</td>\n",
       "      <td>Sierra Club</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1578052076</td>\n",
       "      <td>1578052076.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/619KxYEq...</td>\n",
       "      <td>Sierra Club Wilderness Calendar 2016</td>\n",
       "      <td>Sierra Club</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    761183272  0761183272.jpg  \\\n",
       "0  1623439671  1623439671.jpg   \n",
       "1  B00O80WC6I  B00O80WC6I.jpg   \n",
       "2   761182187  0761182187.jpg   \n",
       "3  1578052084  1578052084.jpg   \n",
       "4  1578052076  1578052076.jpg   \n",
       "\n",
       "  http://ecx.images-amazon.com/images/I/61Y5cOdHJbL.jpg  \\\n",
       "0  http://ecx.images-amazon.com/images/I/61t-hrSw...      \n",
       "1  http://ecx.images-amazon.com/images/I/41X-KQqs...      \n",
       "2  http://ecx.images-amazon.com/images/I/61j-4gxJ...      \n",
       "3  http://ecx.images-amazon.com/images/I/51Ry4Tsq...      \n",
       "4  http://ecx.images-amazon.com/images/I/619KxYEq...      \n",
       "\n",
       "                     Mom's Family Wall Calendar 2016      Sandra Boynton  3  \\\n",
       "0                    Doug the Pug 2016 Wall Calendar        Doug the Pug  3   \n",
       "1  Moleskine 2016 Weekly Notebook, 12M, Large, Bl...           Moleskine  3   \n",
       "2            365 Cats Color Page-A-Day Calendar 2016  Workman Publishing  3   \n",
       "3               Sierra Club Engagement Calendar 2016         Sierra Club  3   \n",
       "4               Sierra Club Wilderness Calendar 2016         Sierra Club  3   \n",
       "\n",
       "   Calendars  \n",
       "0  Calendars  \n",
       "1  Calendars  \n",
       "2  Calendars  \n",
       "3  Calendars  \n",
       "4  Calendars  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Renaming columns and splitting into feature(title) and target(genre) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###dsa as as \n",
    "columns = ['Id', 'Image', 'Image_link', 'Title', 'Author', 'Class', 'Genre']\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Image</th>\n",
       "      <th>Image_link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Class</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>446552313</td>\n",
       "      <td>0446552313.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51qTC5YF...</td>\n",
       "      <td>The Bible of Unspeakable Truths</td>\n",
       "      <td>Greg Gutfeld</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>140280243</td>\n",
       "      <td>0140280243.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51CiSRkd...</td>\n",
       "      <td>A Treasury of Royal Scandals: The Shocking Tru...</td>\n",
       "      <td>Michael Farquhar</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>316236772</td>\n",
       "      <td>0316236772.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51G8BEDi...</td>\n",
       "      <td>Beautifully Unique Sparkleponies: On Myths, Mo...</td>\n",
       "      <td>Chris Kluwe</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>609804618</td>\n",
       "      <td>0609804618.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/519uo9GI...</td>\n",
       "      <td>Our Dumb Century: The Onion Presents 100 Years...</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>62320408</td>\n",
       "      <td>0062320408.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51U1SfEk...</td>\n",
       "      <td>President Me: The America That's in My Head</td>\n",
       "      <td>Adam Carolla</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>1400048575</td>\n",
       "      <td>1400048575.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MXTST8...</td>\n",
       "      <td>A Right to Be Hostile: The Boondocks Treasury</td>\n",
       "      <td>Aaron McGruder</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>449208397</td>\n",
       "      <td>0449208397.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51PwqZDv...</td>\n",
       "      <td>If Life Is a Bowl of Cherries, What Am I Doing...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>1101906073</td>\n",
       "      <td>1101906073.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41ABM1D8...</td>\n",
       "      <td>The Deleted E-Mails of Hillary Clinton: A Parody</td>\n",
       "      <td>John Moe</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>345336976</td>\n",
       "      <td>0345336976.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51o7Ik9i...</td>\n",
       "      <td>Without Feathers</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>692501940</td>\n",
       "      <td>0692501940.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51lDqKfc...</td>\n",
       "      <td>Trump 2016: Off-Color Coloring Book (Off-Color...</td>\n",
       "      <td>Tom F. O'Leary</td>\n",
       "      <td>13</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id           Image  \\\n",
       "20000   446552313  0446552313.jpg   \n",
       "20001   140280243  0140280243.jpg   \n",
       "20002   316236772  0316236772.jpg   \n",
       "20003   609804618  0609804618.jpg   \n",
       "20004    62320408  0062320408.jpg   \n",
       "20005  1400048575  1400048575.jpg   \n",
       "20006   449208397  0449208397.jpg   \n",
       "20007  1101906073  1101906073.jpg   \n",
       "20008   345336976  0345336976.jpg   \n",
       "20009   692501940  0692501940.jpg   \n",
       "\n",
       "                                              Image_link  \\\n",
       "20000  http://ecx.images-amazon.com/images/I/51qTC5YF...   \n",
       "20001  http://ecx.images-amazon.com/images/I/51CiSRkd...   \n",
       "20002  http://ecx.images-amazon.com/images/I/51G8BEDi...   \n",
       "20003  http://ecx.images-amazon.com/images/I/519uo9GI...   \n",
       "20004  http://ecx.images-amazon.com/images/I/51U1SfEk...   \n",
       "20005  http://ecx.images-amazon.com/images/I/51MXTST8...   \n",
       "20006  http://ecx.images-amazon.com/images/I/51PwqZDv...   \n",
       "20007  http://ecx.images-amazon.com/images/I/41ABM1D8...   \n",
       "20008  http://ecx.images-amazon.com/images/I/51o7Ik9i...   \n",
       "20009  http://ecx.images-amazon.com/images/I/51lDqKfc...   \n",
       "\n",
       "                                                   Title            Author  \\\n",
       "20000                    The Bible of Unspeakable Truths      Greg Gutfeld   \n",
       "20001  A Treasury of Royal Scandals: The Shocking Tru...  Michael Farquhar   \n",
       "20002  Beautifully Unique Sparkleponies: On Myths, Mo...       Chris Kluwe   \n",
       "20003  Our Dumb Century: The Onion Presents 100 Years...         The Onion   \n",
       "20004        President Me: The America That's in My Head      Adam Carolla   \n",
       "20005      A Right to Be Hostile: The Boondocks Treasury    Aaron McGruder   \n",
       "20006  If Life Is a Bowl of Cherries, What Am I Doing...      Erma Bombeck   \n",
       "20007   The Deleted E-Mails of Hillary Clinton: A Parody          John Moe   \n",
       "20008                                   Without Feathers       Woody Allen   \n",
       "20009  Trump 2016: Off-Color Coloring Book (Off-Color...    Tom F. O'Leary   \n",
       "\n",
       "       Class                  Genre  \n",
       "20000     13  Humor & Entertainment  \n",
       "20001     13  Humor & Entertainment  \n",
       "20002     13  Humor & Entertainment  \n",
       "20003     13  Humor & Entertainment  \n",
       "20004     13  Humor & Entertainment  \n",
       "20005     13  Humor & Entertainment  \n",
       "20006     13  Humor & Entertainment  \n",
       "20007     13  Humor & Entertainment  \n",
       "20008     13  Humor & Entertainment  \n",
       "20009     13  Humor & Entertainment  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[20000:20010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "books = pd.DataFrame(data['Title'])\n",
    "genre = pd.DataFrame(data['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print (type(books))\n",
    "print (type(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207571, 1)\n",
      "(207571, 1)\n"
     ]
    }
   ],
   "source": [
    "print (books.shape)\n",
    "print (genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating our vocabulary\n",
    "\n",
    "Counting how many times a word appears in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  151193\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_counts = Counter()\n",
    "for i in range(len(books)):\n",
    "    for word in books.values[i][0].split(\" \"):\n",
    "        total_counts[word] += 1\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sorting in decreasing order (Word with highest frequency appears first)\n",
    "\n",
    "We only use the first 20000 words for our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'of', 'The', 'the', 'to', 'A', 'in', 'for', 'Guide', '&', 'a', 'Your', 'Book', 'with', 'Edition', 'How', 'Edition)', 'on', '-', 'from', 'New', 'Series)', 'An', 'Life', 'You', 'World', 'History', 'by', 'Recipes', 'Complete', 'American', '(The', 'For', 'Story', 'My', 'Travel', 'Art', '', '(Volume', 'Volume', 'Law', 'Calendar', 'Health', 'From', 'To', 'And', 'Handbook', 'at', 'Best', 'Novel', 'In', 'What', 'I', 'With', 'Practice', 'Science', 'Great', 'Vol.', 'Introduction', 'Of']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:20000]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trademarks :  8\n"
     ]
    }
   ],
   "source": [
    "# Last word shows up \n",
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Mapping from words to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "word2idx = {}\n",
    "#print vocab_size\n",
    "for i, word in enumerate(vocab):\n",
    "    word2idx[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Helper Function to convert all Titles to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vector = np.zeros(vocab_size)\n",
    "    for word in text.split(\" \"):\n",
    "        if word2idx.get(word) is None:\n",
    "            continue\n",
    "        else:\n",
    "            word_vector[word2idx.get(word)] += 1\n",
    "    return np.array(word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Vector created as follow :\n",
    "positions with respect to highest occuring word\n",
    "\n",
    "Eg : 1 at first index means first word in vocab(most frequent occuring in vocab which is 'of') occurs twice in this sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector(\"I am of a Legend\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Convert all titles to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(books), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(books.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207571, 20000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_vectors[:5, :23]\n",
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>203470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tao Te Ching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title\n",
       "count         207571\n",
       "unique        203470\n",
       "top     Tao Te Ching\n",
       "freq              11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>18338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Genre\n",
       "count   207571\n",
       "unique      32\n",
       "top     Travel\n",
       "freq     18338"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#genre_ = pd.get_dummies(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207541</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207542</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207543</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207544</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207545</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207546</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207547</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207548</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207549</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207550</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207551</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207552</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207553</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207554</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207555</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207556</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207557</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207558</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207559</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207560</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207561</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207562</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207563</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207564</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207565</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207566</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207567</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207568</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207569</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207570</th>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207571 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Genre\n",
       "0       Calendars\n",
       "1       Calendars\n",
       "2       Calendars\n",
       "3       Calendars\n",
       "4       Calendars\n",
       "5       Calendars\n",
       "6       Calendars\n",
       "7       Calendars\n",
       "8       Calendars\n",
       "9       Calendars\n",
       "10      Calendars\n",
       "11      Calendars\n",
       "12      Calendars\n",
       "13      Calendars\n",
       "14      Calendars\n",
       "15      Calendars\n",
       "16      Calendars\n",
       "17      Calendars\n",
       "18      Calendars\n",
       "19      Calendars\n",
       "20      Calendars\n",
       "21      Calendars\n",
       "22      Calendars\n",
       "23      Calendars\n",
       "24      Calendars\n",
       "25      Calendars\n",
       "26      Calendars\n",
       "27      Calendars\n",
       "28      Calendars\n",
       "29      Calendars\n",
       "...           ...\n",
       "207541     Travel\n",
       "207542     Travel\n",
       "207543     Travel\n",
       "207544     Travel\n",
       "207545     Travel\n",
       "207546     Travel\n",
       "207547     Travel\n",
       "207548     Travel\n",
       "207549     Travel\n",
       "207550     Travel\n",
       "207551     Travel\n",
       "207552     Travel\n",
       "207553     Travel\n",
       "207554     Travel\n",
       "207555     Travel\n",
       "207556     Travel\n",
       "207557     Travel\n",
       "207558     Travel\n",
       "207559     Travel\n",
       "207560     Travel\n",
       "207561     Travel\n",
       "207562     Travel\n",
       "207563     Travel\n",
       "207564     Travel\n",
       "207565     Travel\n",
       "207566     Travel\n",
       "207567     Travel\n",
       "207568     Travel\n",
       "207569     Travel\n",
       "207570     Travel\n",
       "\n",
       "[207571 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(genre)\n",
    "len(genre)\n",
    "genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementing the same alogorithm to map genres to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  63\n"
     ]
    }
   ],
   "source": [
    "## Counting how many times a word appears in the dataset\n",
    "from collections import Counter\n",
    "\n",
    "total_counts_genre = Counter()\n",
    "for i in range(len(genre)):\n",
    "    for word in genre.values[i][0].split(\" \"):\n",
    "        total_counts_genre[word] += 1\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Books', 'Travel', \"Children's\", 'Science', 'Medical', 'Health,', 'Fitness', 'Dieting', 'Fiction', 'Business', 'Money', 'Crafts,', 'Hobbies', 'Home', 'Math', 'Christian', 'Bibles', 'Cookbooks,', 'Food', 'Wine', 'Computers', 'Technology', 'Literature', 'Religion', 'Spirituality', 'Teen', 'Young', 'Adult', 'Law', 'Humor', 'Entertainment', 'History', 'Arts', 'Photography', 'Sports', 'Outdoors', 'Romance', 'Biographies', 'Memoirs', 'Fantasy', 'Politics', 'Social', 'Sciences', 'Reference', 'Comics', 'Graphic', 'Novels', 'Test', 'Preparation', 'Self-Help', 'Engineering', 'Transportation', 'Calendars', 'Parenting', 'Relationships', 'Mystery,', 'Thriller', 'Suspense', 'Education', 'Teaching', 'Gay', 'Lesbian']\n"
     ]
    }
   ],
   "source": [
    "vocab_genre = sorted(total_counts_genre, key=total_counts_genre.get, reverse=True)\n",
    "\n",
    "## Removimg '&' as first element\n",
    "vocab_genre = vocab_genre[1:]\n",
    "print (vocab_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lesbian :  1339\n"
     ]
    }
   ],
   "source": [
    "print(vocab_genre[-1], ': ', total_counts_genre[vocab_genre[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size_genre = len(vocab_genre)\n",
    "word2idx_genre = {}\n",
    "#print vocab_size\n",
    "for i, word in enumerate(vocab_genre):\n",
    "    word2idx_genre[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector_genre(text):\n",
    "    word_vector_genre = np.zeros(vocab_size_genre)\n",
    "    for word in text.split(\" \"):\n",
    "        if word2idx_genre.get(word) is None:\n",
    "            continue\n",
    "        else:\n",
    "            word_vector_genre[word2idx_genre.get(word)] += 1\n",
    "    return np.array(word_vector_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_vectors_genre = np.zeros((len(genre), len(vocab_genre)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(genre.iterrows()):\n",
    "    word_vectors_genre[ii] = text_to_vector_genre(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_genre.shape\n",
    "word_vectors_genre[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207571, 20000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Books',\n",
       " 'Travel',\n",
       " \"Children's\",\n",
       " 'Science',\n",
       " 'Medical',\n",
       " 'Health,',\n",
       " 'Fitness',\n",
       " 'Dieting',\n",
       " 'Fiction',\n",
       " 'Business',\n",
       " 'Money',\n",
       " 'Crafts,',\n",
       " 'Hobbies',\n",
       " 'Home',\n",
       " 'Math',\n",
       " 'Christian',\n",
       " 'Bibles',\n",
       " 'Cookbooks,',\n",
       " 'Food',\n",
       " 'Wine',\n",
       " 'Computers',\n",
       " 'Technology',\n",
       " 'Literature',\n",
       " 'Religion',\n",
       " 'Spirituality',\n",
       " 'Teen',\n",
       " 'Young',\n",
       " 'Adult',\n",
       " 'Law',\n",
       " 'Humor',\n",
       " 'Entertainment',\n",
       " 'History',\n",
       " 'Arts',\n",
       " 'Photography',\n",
       " 'Sports',\n",
       " 'Outdoors',\n",
       " 'Romance',\n",
       " 'Biographies',\n",
       " 'Memoirs',\n",
       " 'Fantasy',\n",
       " 'Politics',\n",
       " 'Social',\n",
       " 'Sciences',\n",
       " 'Reference',\n",
       " 'Comics',\n",
       " 'Graphic',\n",
       " 'Novels',\n",
       " 'Test',\n",
       " 'Preparation',\n",
       " 'Self-Help',\n",
       " 'Engineering',\n",
       " 'Transportation',\n",
       " 'Calendars',\n",
       " 'Parenting',\n",
       " 'Relationships',\n",
       " 'Mystery,',\n",
       " 'Thriller',\n",
       " 'Suspense',\n",
       " 'Education',\n",
       " 'Teaching',\n",
       " 'Gay',\n",
       " 'Lesbian']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (word_vectors.shape)\n",
    "word_vectors_genre[1]\n",
    "list(word2idx_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Spliting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_vectors, word_vectors_genre, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155678, 20000)\n",
      "(155678, 62)\n",
      "(51893, 20000)\n",
      "(51893, 62)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input\n",
    "    net = tflearn.input_data([None, 20000])\n",
    "    \n",
    "    #Hidden\n",
    "    net = tflearn.fully_connected(net, 128, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 128, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 128, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 256, activation='ReLU')\n",
    "\n",
    "    ## Dropout\n",
    "    net = tflearn.layers.core.dropout (net, 0.5, noise_shape=None, name='Dropout')\n",
    "\n",
    "    #Output\n",
    "    net = tflearn.fully_connected(net, 62, activation='softmax') \n",
    "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.003, loss='categorical_crossentropy')\n",
    "    \n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 46219  | total loss: \u001b[1m\u001b[32m3.26348\u001b[0m\u001b[0m | time: 183.693s\n",
      "| Adam | epoch: 010 | loss: 3.26348 - acc: 0.4876 -- iter: 147872/147894\n",
      "Training Step: 46220  | total loss: \u001b[1m\u001b[32m3.17957\u001b[0m\u001b[0m | time: 187.356s\n",
      "| Adam | epoch: 010 | loss: 3.17957 - acc: 0.4920 | val_loss: 6.87093 - val_acc: 0.3231 -- iter: 147894/147894\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_set=0.05, show_metric=True, batch_size=32, n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/akshaybhatia/Desktop/Spikeway AI Internship/book-dataset/Task2/models/Basic.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "## save the model\n",
    "model.save('models/Basic.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/akshaybhatia/Desktop/Spikeway AI Internship/book-dataset/Task2/models/Basic.tfl\n"
     ]
    }
   ],
   "source": [
    "model.load(\"models/Basic.tfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "## Predictions for first book in testing set\n",
    "print (len(X_test[1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.030702032148838043, 0.010740121826529503, 0.021121108904480934, 0.05105367675423622, 0.0013459111796692014, 0.0018938007997348905, 0.0018584177596494555, 0.0018679560162127018, 0.14497590065002441, 0.0005127931945025921, 0.0005039435345679522, 0.0015564949717372656, 0.0015988099621608853, 0.0016039994079619646, 0.002526502124965191, 0.00745767168700695, 0.007449390832334757, 0.0003610215208027512, 0.00037011198583059013, 0.00035533373011276126, 0.0010298164561390877, 0.001046090037561953, 0.12750568985939026, 0.006428136490285397, 0.006503743585199118, 0.04152499511837959, 0.04226037487387657, 0.04301370307803154, 0.0025409578811377287, 0.016943149268627167, 0.01668836921453476, 0.0035385936498641968, 0.005658373236656189, 0.005907632410526276, 0.0023282666224986315, 0.002264992566779256, 0.11412695050239563, 0.007894408889114857, 0.00796525552868843, 0.05198577418923378, 0.0019442636985331774, 0.0019404711201786995, 0.0019378394354134798, 0.002734596375375986, 0.007940965704619884, 0.008189377374947071, 0.008124854415655136, 0.0001431737036909908, 0.00014306798402685672, 0.0006461556768044829, 0.00014297796587925404, 0.0001466122193960473, 1.1073480891354848e-05, 0.0028927111998200417, 0.002974544884636998, 0.053220853209495544, 0.0525556318461895, 0.051687031984329224, 0.00012814896763302386, 0.00014739717880729586, 0.0026596663519740105, 0.002678381046280265]]\n"
     ]
    }
   ],
   "source": [
    "text = \"Lord of the Rings: Return of the King\" ## Genre is Christian Books and Bible\n",
    "prob = model.predict([text_to_vector(text)])\n",
    "print (prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.14497590065002441, 8), (0.12750568985939026, 22), (0.11412695050239563, 36), (0.053220853209495544, 55), (0.0525556318461895, 56)]\n"
     ]
    }
   ],
   "source": [
    "results = sorted(((value, index) for index, value in enumerate(prob[0])), reverse=True)[:5]\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying top 5 genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiction\n",
      "Literature\n",
      "Romance\n",
      "Mystery,\n",
      "Thriller\n"
     ]
    }
   ],
   "source": [
    "### Predictions \n",
    "\n",
    "originial_genre_vocab = list(word2idx_genre)\n",
    "#originial_genre_vocab[:10]\n",
    "for i,j in results:\n",
    "    print (originial_genre_vocab[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
